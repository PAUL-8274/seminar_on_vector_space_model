{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "doc_trump = \"Mr. Trump became president after winning the political election. Though h e lost the support of some republican friends, Trump is friends with President Putin\"  \n",
    "doc_election = \"President Trump says Putin had no political interference is the electi on outcome. He says it was a witchhunt by political parties. He claimed President Puti n is a friend who had nothing to do with the election\"  \n",
    "doc_putin = \"Post elections, Vladimir Putin became President of Russia. President Puti n had served as the Prime Minister earlier in his political career\"  \n",
    "documents = [doc_trump, doc_election, doc_putin] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit Learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.feature_extraction.text  import CountVectorizer \n",
    "import pandas as pd  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Document Term Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "count_vectorizer = CountVectorizer(stop_words='english') \n",
    "count_vectorizer = CountVectorizer() \n",
    "sparse_matrix = count_vectorizer.fit_transform(documents)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPTIONAL: Convert Sparse Matrix to Pandas Dataframe if you want to see the word freq uencies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>after</th>\n",
       "      <th>as</th>\n",
       "      <th>became</th>\n",
       "      <th>by</th>\n",
       "      <th>career</th>\n",
       "      <th>claimed</th>\n",
       "      <th>do</th>\n",
       "      <th>earlier</th>\n",
       "      <th>electi</th>\n",
       "      <th>election</th>\n",
       "      <th>...</th>\n",
       "      <th>the</th>\n",
       "      <th>though</th>\n",
       "      <th>to</th>\n",
       "      <th>trump</th>\n",
       "      <th>vladimir</th>\n",
       "      <th>was</th>\n",
       "      <th>who</th>\n",
       "      <th>winning</th>\n",
       "      <th>witchhunt</th>\n",
       "      <th>with</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>doc_trump</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_election</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_putin</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              after  as  became  by  career  claimed  do  earlier  electi  \\\n",
       "doc_trump         1   0       1   0       0        0   0        0       0   \n",
       "doc_election      0   0       0   1       0        1   1        0       1   \n",
       "doc_putin         0   1       1   0       1        0   0        1       0   \n",
       "\n",
       "              election  ...  the  though  to  trump  vladimir  was  who  \\\n",
       "doc_trump            1  ...    2       1   0      2         0    0    0   \n",
       "doc_election         1  ...    2       0   1      1         0    1    1   \n",
       "doc_putin            0  ...    1       0   0      0         1    0    0   \n",
       "\n",
       "              winning  witchhunt  with  \n",
       "doc_trump           1          0     1  \n",
       "doc_election        0          1     1  \n",
       "doc_putin           0          0     0  \n",
       "\n",
       "[3 rows x 51 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "doc_term_matrix = sparse_matrix.todense() \n",
    "df = pd.DataFrame(doc_term_matrix,columns=count_vectorizer.get_feature_names(),index=['doc_trump', 'doc_election', 'doc_putin']) \n",
    "df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Cosine Similarity \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.4361843  0.37450294]\n",
      " [0.4361843  1.         0.35745328]\n",
      " [0.37450294 0.35745328 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "print(cosine_similarity(df, df))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "without library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transpose=df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lis1=df_transpose.doc_trump.tolist()\n",
    "lis2=df_transpose.doc_election.tolist()\n",
    "lis3=df_transpose.doc_putin.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from math import sqrt\n",
    "\n",
    "def cosine_sim(list1,list2):      #list are list of count of different words\n",
    "    summ=0\n",
    "    v1=0\n",
    "    v2=0\n",
    "    for i,j in zip(list1,list2):\n",
    "        summ+=(i*j)\n",
    "        v1+=(i*i)\n",
    "        v2+=(j*j)\n",
    "    cossim=summ/(sqrt(v1)*sqrt(v2))\n",
    "    return cossim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3745029431365692"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim(lis1,lis3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " we are getting the similarity between doc_trump and doc_putin,which is exactly similar to the sklearn library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# soft cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the documents \n",
    "doc_soup = \"Soup is a primarily liquid food, generally served warm or hot (but may be cool or cold), that is made by combining ingredients of meat or vegetables with stoc k, juice, water, or another liquid. \"  \n",
    "doc_noodles = \"Noodles are a staple food in many cultures. They are made from unleaven ed dough which is stretched, extruded, or rolled flat and cut into one of a variety of shapes.\"  \n",
    "doc_dosa = \"Dosa is a type of pancake from the Indian subcontinent, made from a fermen ted batter. It is somewhat similar to a crepe in appearance. Its main ingredients are rice and black gram.\"  \n",
    "documents = [doc_trump, doc_election, doc_putin, doc_soup, doc_noodles, doc_dosa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport gensim # upgrade gensim if you can't import softcossim \\nfrom gensim.matutils import softcossim  \\nfrom gensim import corpora \\nimport gensim.downloader as api \\nfrom gensim.utils import simple_preprocess \\nprint(gensim.__version__) #> '3.6.0'  \\n# Download the FastText model \\nfasttext_model300 = api.load('fasttext-wiki-news-subwords-300') \\n\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import gensim # upgrade gensim if you can't import softcossim \n",
    "from gensim.matutils import softcossim  \n",
    "from gensim import corpora \n",
    "import gensim.downloader as api \n",
    "from gensim.utils import simple_preprocess \n",
    "print(gensim.__version__) #> '3.6.0'  \n",
    "# Download the FastText model \n",
    "fasttext_model300 = api.load('fasttext-wiki-news-subwords-300') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim # upgrade gensim if you can't import softcossim from gensim.matutils import softcossim  from gensim import corpora import gensim.downloader as api from gensim.utils import simple_preprocess print(gensim.__version__) #> '3.6.0'  \n",
    "# Download the FastText model fasttext_model300 = api.load('fasttext-wiki-news-subwords-300') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a dictionary and a corpus. \n",
    "dictionary = corpora.Dictionary([simple_preprocess(doc) for doc in documents])  \n",
    "# Prepare the similarity matrix \n",
    "similarity_matrix = fasttext_model300.similarity_matrix(dictionary, tfidf=None, thresh old=0.0, exponent=2.0, nonzero_limit=100)  \n",
    "# Convert the sentences into bag-of-words vectors. \n",
    "sent_1 = dictionary.doc2bow(simple_preprocess(doc_trump)) \n",
    "sent_2 = dictionary.doc2bow(simple_preprocess(doc_election)) \n",
    "sent_3 = dictionary.doc2bow(simple_preprocess(doc_putin)) \n",
    "sent_4 = dictionary.doc2bow(simple_preprocess(doc_soup)) \n",
    "sent_5 = dictionary.doc2bow(simple_preprocess(doc_noodles)) \n",
    "sent_6 = dictionary.doc2bow(simple_preprocess(doc_dosa))  \n",
    "sentences = [sent_1, sent_2, sent_3, sent_4, sent_5, sent_6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want the soft cosine similarity of 2 documents, you can just call the softcossim() function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute soft cosine similarity \n",
    "print(softcossim(sent_1, sent_2, similarity_matrix)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, I want to compare the soft cosines for all documents against each other. So, create the soft cosine similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd  \n",
    "def create_soft_cossim_matrix(sentences):     \n",
    "    len_array = np.arange(len(sentences))     \n",
    "    xx, yy = np.meshgrid(len_array, len_array)     \n",
    "    cossim_mat = pd.DataFrame([[round(softcossim(sentences[i],sentences[j], similarity _matrix) ,2) for i, j in zip(x,y)] for y, x in zip(xx, yy)])     \n",
    "    return cossim_mat  \n",
    "soft_cosine_similarity_matrix(sentences) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one might expect, the similarity scores amongst similar documents are higher "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All copyrights are reserved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
